# Importa la librer√≠a Streamlit para crear la interfaz web
import streamlit as st
# Importa el modelo OllamaLLM de langchain_ollama para procesamiento de lenguaje natural
from langchain_ollama import OllamaLLM
# Importa la plantilla de prompts para chat de langchain_core
from langchain_core.prompts import ChatPromptTemplate
# Importa la lista de productos desde el archivo productos.py
from productos import productos
# Importa la librer√≠a de expresiones regulares (no se usa en este c√≥digo)
import re

# Importa la informaci√≥n del negocio desde infonegocio.py
from infonegocio import info

# Configura la p√°gina de Streamlit (t√≠tulo y dise√±o)
st.set_page_config(page_title="F√∫tbol de Hermanos", layout="wide")
# Muestra el t√≠tulo principal en la p√°gina
st.title("üèÜ Futbol de Hermanos")
# Muestra una breve descripci√≥n debajo del t√≠tulo
st.write("F√∫tbol de Hermanos, m√°s que una tienda, una pasi√≥n por el deporte.")

# Muestra el logo en la barra lateral
st.sidebar.image("images/Logo FUTBOL DE HERMANOS.jpg", use_container_width=True)
# T√≠tulo en la barra lateral
st.sidebar.title("F√∫tbol de Hermanos")
# Informaci√≥n de contacto en la barra lateral
st.sidebar.markdown("üìç *Guadalajara, Jalisco*")
st.sidebar.markdown("üìû +52 55 1234 5678")
st.sidebar.markdown("üìß futboldehermanos@gmail.com")
st.sidebar.markdown("üåê [Sitio Web](https://futboldehermanos.com)")

# Funci√≥n para buscar productos que coincidan con el mensaje del usuario
def buscar_producto(mensaje):
    mensaje = mensaje.lower()  # Convierte el mensaje a min√∫sculas
    encontrados = []  # Lista para productos encontrados
    for producto in productos:  # Recorre todos los productos
        # Si alg√∫n alias del producto est√° en el mensaje, lo agrega a la lista
        if any(alias in mensaje for alias in producto["alias"]):
            encontrados.append(producto)
    return encontrados  # Devuelve la lista de productos encontrados

# Inicializa el historial de mensajes si no existe en la sesi√≥n
if "messages" not in st.session_state:
    st.session_state.messages = []

# Inicializa el indicador de primer mensaje si no existe en la sesi√≥n
if "first_message" not in st.session_state:
    st.session_state.first_message = True

# Muestra el historial de chat almacenado en la sesi√≥n
for message in st.session_state.messages:
    with st.chat_message(message["role"]):  # Muestra el mensaje seg√∫n el rol (usuario o asistente)
        st.markdown(message["content"])

# Si es la primera vez que se carga la p√°gina, muestra el saludo inicial del bot
if st.session_state.first_message:
    saludo = "Hola, te saluda tu asistente de venta BOTin ü§ñ‚öΩ. ¬øC√≥mo puedo ayudarte hoy?"
    with st.chat_message("assistant"):
        st.markdown(saludo)
    st.session_state.messages.append({"role": "assistant", "content": saludo})
    st.session_state.first_message = False  # Marca que ya no es el primer mensaje

# Configura el modelo LLaMA y la cadena de procesamiento si no existe en la sesi√≥n
if "ollama" not in st.session_state:
    # Plantilla para el prompt que se enviar√° al modelo
    template = """
    Responde la siguiente pregunta en espa√±ol.

    Aqu√≠ est√° el contexto del negocio: 
    {infonegocio}

    {context}

    Pregunta: {question}

    Respuesta:
    """
    # Inicializa el modelo OllamaLLM con el modelo llama3.1
    model = OllamaLLM(model="llama3.1")
    # Crea el prompt a partir de la plantilla
    prompt = ChatPromptTemplate.from_template(template)
    # Crea la cadena de procesamiento combinando prompt y modelo
    chain = prompt | model
    # Inicializa el contexto como cadena vac√≠a
    context = ""

# Captura la entrada del usuario desde el chat
if user_input := st.chat_input("Escribe tu pregunta aqu√≠..."):
    # Muestra el mensaje del usuario en el chat
    with st.chat_message("user"):
        st.markdown(user_input)

    # Agrega el mensaje del usuario al historial de mensajes
    st.session_state.messages.append({
        "role": "user",
        "content": user_input
    })

    # Invoca el modelo con el contexto, la informaci√≥n del negocio y la pregunta del usuario
    result = chain.invoke({
        "infonegocio": info,
        "context": context,
        "question": user_input
    })

    # Busca productos relacionados con la pregunta del usuario
    productos_encontrados = buscar_producto(user_input)

    # Muestra la respuesta del asistente y los productos encontrados
    with st.chat_message("assistant"):
        st.markdown(result)
        for producto in productos_encontrados:
            st.image(producto["imagen"], use_column_width=True)
            st.markdown(f"### {producto['nombre']}")
            st.markdown(f"üíµ **Precio:** {producto['precio']}")
            st.markdown(f"üìå **Tallas disponibles:** {producto['tallas']}")
            with st.expander("üßµ Ver caracter√≠sticas"):
                st.markdown(producto["caracteristicas"])

    # Agrega la respuesta del asistente al historial de mensajes
    st.session_state.messages.append({
        "role": "assistant",
        "content": result
    })

    # Actualiza el contexto con la √∫ltima interacci√≥n
    context += f"T√∫: {user_input}\nBot: {result}\n"
